---
title: 技术方案 Webinar - 使用 AI 编程
date: 2023-04-01 20:55:03
sidebar: true
head:
- - meta
- name: keyword
  content: AI，编程
  description: 使用 AI 编程
---


## AI 基本知识

- AI：人工智能，通过计算机的算力实现类似人类的智能。
- 机器学习：机器学习是实现 AI 的一种方式，通过计算机模拟人类对知识的摄取。
- 深度学习：深度学习是通过神经网络的方式实现机器学习，是一种机器学习的实现路线。
- 机器学习中深度学习的基本原理为：基于反馈（反向传播）的学习，模拟人脑，人脑的工作模式其实非常简单——基于反馈（正反馈、负反馈）调整神经元的链接方式（可以认为是一种程序）。也就是说，基于反向传播的深度学习通俗的来说就是基于语料和反馈，自动调整模型参数，加速了学习过程，并实现涌现。
- 深度学习寒冬：在 AI 领域展现出性能前，深度学习这个发展方向不受认可。直到通过显卡和性能提升后，深度学习寒冬方能结束。
- 显卡和深度学习的关系：CPU 的计算单元非常有限，主要是调度单元，它的计算特性是精度非常高。GPU 的特点是精度不高，计算单元非常多，类似小型超算。神经网络对单个单元的误差不敏感，这就是为什么 GPU 的效率更高。通过 CPU 把信息从内存搬到显存中，然后并行计算。关键的点是，GPU 可以大规模并行计算。
- GPU 为什么比 CPU 可以提高并行性和高性能？不依赖计算结果依赖。
- NLU：自然语言理解，先去理解意图（Intend）。识别关键字，并且识别关键字的逻辑管理，并可以被生成能被处理的形式化语言。
- NLG: 自然语言生成，生成合适的返回。有两种方式，生成式（直接使用人工神经网络，一度程度上就代表智能了）和模板匹配（神经网络只做 NLU）。
- 大规模遗忘、灾难性遗忘：如果开放自动沉淀功能给 ChatGPT，原始模型可能会被大规模输入干扰 AI 的智能，比如喂了一本书给 AI，如果更多的资料输入会把原来的模型覆盖。一个比喻是柏拉图的蜡版学说，一个人的智力就像蜡版上刻画的线条，如果过多的刻画那么信息会淹没原来的信息。

## 如何使用 ChatGPT？

### ChatGPT 3 的基本使用 

- 挂 VPN
  - 树洞
- 收号平台
  - sms-active.org

### ChatGPT GPT-4 的申请

- 如果海外的信用卡才能顺利申请
 
### 代替平台

目前还没有复刻 ChatGPT 的相似系统，OpenAI 目前处于领先状态，在训练的最后一个阶段人工强化训练，目前还没有团队能复刻。

目前大部分代替性平台都是使用 OpenAI 的开放 API，而微软等巨头拥有 ChatGPT 模型相关的所有权。Adobe 公司使用的模型属于图像（CV）特定领域 AI 技术，和 ChatGPT 这类自然语言（NLP）处理不相同。

AIGC 的划分方法，是以内容生成为出发点，包括了图像（AI 作画）、自然语言（NLG）。

- https://poe.com ChatGPT3/4 模型
- https://www.midjourney.com 图像生成 
- https://cc.ai55.cc/ AP 导航网站
- https://bito.ai 代码生成器
- https://www.cursor.so 代码生成器
- OpenAI Codex，例如 GitHub Copilot

## 如何高效使用 ChatGPT？

合理的使用 Prompt 可以提高使用效率，已经演变为了一种专业领域 Prompt Engineering。

ChatGPT 的工作有两个过程：

- 预训练模型/沉淀模型
- 预测和生成阶段，在当前上下文中教会 AI 的过程就是 Prompt
- 现在 ChatGPT 不具备自动沉淀的能力，因此高效使用 ChatGPT 的技巧就是设计 Prompt，也就是如何教会 AI 做事情。
- Prompt 这一步本质和预训练本质上没有区别，只是在模型外部存在 Prompt 中。

ChatGPT 的输入不是当前的问题作为参数，而是整个上下文的内容作为参数输入模型，通过改变上下文来优化模型的结果。

使用 ChatGPT 最高效的方式是：

- 教会 AI。可以通过对话上下文输入知识，也可以通过调用 API 提前设定规则。
- 提一个好问题。如果把 AI 引导到错误的方向，可以选择退出当前对话，清空上下文。

Prompt Engineering 是一个教会 AI 学问，已经发展为一个专业领域。Prompt 的内涵是： 通过提示模型改变模型在预测时的行为。目前 Prompt 在 ChatGPT 中就是文本材料。

Prompt 类似于早期 IBM 的沃森意图预测后的规则设定。

以后可能会在 Github 上出现大量的 Prompt 库，这样以后只需要调用相关的 Prompt 并输入给 AI，就可以在工作中高效的使用 AI。

## 如何在工作中使用 AI 提高生产力？

- 使用认知分级来高效利用 AI。比如将工作进行分级，将高认知、复杂、混乱有人工完成，将固定模式的内容交给【当前阶段水平的 AI】来完成。
- 学习别人如何做 Prompt，成为一个 Prompt 工程师
  - Google Schoolar 上找到 Prompt 的论文，学习相关理论
  - B、YouTube 站上有一些 Prompt 教程
- Prompt 可能会市场化、开源化，关注市场上出现的 Prompt 的产品
- 怎么大规模喂数据给 ChatGPT？通过 API
- 常用的工具提高生产力：
  - 因为 ChatGPT 没有沉淀能力，需要自己记录 Prompt 知识库，目前开源社区已经如火如荼
  - IntelliJ 插件：
  - VSCode 插件：
  - AI 命令行工具：warp
- 如果没有互联网络，或者数据敏感，能用上 AI 相关的技术吗？
  - ChatGPT 不行，依赖 OpenAI 的开放 API
  - 一些小的模型可以在内网部署，但是不需要本地训练

## 怎么避免被 AI 替代？

- 系统分析层面、上下文多、领域知识多的领域很难被 AI 替代。
- 程序员的工作：对非形式化的领域知识、信息做一个形式化。 非形式化信息（自然语言）→自然语言或者一定程度上的形式化语言。形式化是一个逻辑学概念，形式逻辑。
- 学会用 AI，知道怎么用 AI 做事，而别人不会。
- 关于 AI 吹牛：在历史上每一个技术出现都会有类似的营销方式：重写了一个项目，缩短了 XX 个月的时间，代码量少了 xx%。但不代表 AI 的前景不明朗，目前已经可以看到它的威力。
- 习惯性的使用 AI 代替搜索引擎。

## 关于未来发展的预测

- prompt的前景：prompt 具备边际成本为0，无脑规模化的特效。所以如果某个场景它规模化后有很大价值。那么单次的prompt成本，再高也可能被接受。 关键是喂完能达到理想效果，且模型本身能吃得下。
- 数据隐私和管控：可能未来出现特定领域的专用 ChatGPT。
- AI 生成的内容可能会涉及版权问题，可能存在抄袭。
- 微软的股票可能升值

## 录屏

链接: https://pan.baidu.com/s/1ronIMvLl0FnXwYYSIWOUMg?pwd=gxxy 

